---
title: Notebooks
hide: navigation
---
<!--
SPDX-FileCopyrightText: 2025 German Aerospace Center (DLR)
SPDX-License-Identifier: CC-BY-NC-4.0
-->

<!-- markdownlint-disable-next-line MD025 -->
# Notebooks

The Jupyter Notebooks provided give you a glimpse into what can be achieved using the data generated by our SLKI pipeline.

These notebooks cover a range of topics related to utilizing this pipeline data, including:

- Loading and accessing data
- Understanding pipeline configuration
- Classifying signals
- Detecting anomalies
- Predicting speeds
- And more

We encourage you to delve further into the notebooks.
A good starting point would be our example notebook, which demonstrates how to load and access the data.

## `_defaults.py`

This file contains all basic user settings for all notebooks.
This is where, among other things, it is determined which preprocessed data is loaded from where and how.

The _User Settings_ section is the area you need to set up correctly first before you can run any notebook.

## `example.ipynb`

The example jupyter notebook shows how to load the data, what kind of settings are available and to access to loaded data directly.

The main purpose is to have a starting point and familiarize yourself with the notebook configuration before starting to dig into the data.

## `signal-analyzer.ipynb`

This notebooks loads single signals and offers a simple GUI to plot them including some further analysis.

The prerequisite is to have the SLKI package, its dependencies installed as well as the prepared datasets.
To change the prepared dataset configure the first few cells in the _Load preprecessed datasets_ section.

The main purpose of this jupyter notebook look into single signals.
This notebook also incluses a first version to detect and count train axes in a signal as well as prediction the train speed and signal outliers.

## `metadata-analyse.ipynb`

The metadata analyse jupyter notebook looks a little bit deeper into the metadata.

The prerequisite is to have the SLKI package, its dependencies installed as well as the prepared datasets.
To change the prepared dataset configure the first few cells in the _Load preprecessed datasets_ section.

The main purpose of this jupyter notebook is to look at the different sample lengths and sample rates in Hz of the different datasets and there signals.

## `pipeline-configuration.ipynb`

The pipeline configuration jupyter notebook loads the "raw" datasets and offers you a simple GUI to play around with all possible SLKI pipeline settings as well as pipeline stages and plots the result of a single sample.

The prerequisite is to have the SLKI package, its dependencies installed as well as the prepared "raw" datasets.
To change the prepared dataset configure the first few cells in the _Load preprecessed datasets_ section.

The main purpose of this jupyter notebook is play around with the different pipeline settings and stages.
As a result it is possible to see the changes of each parameter, fine tune them and result in a well defined configuration file.

## Signal classification

We tested multiple approaches to classify train signals into three major classes _Regionalverkehr_, _Fernverkehr_ and _GÃ¼terverker_, and examined various traditional machine learning algorithms, as well as time-series specialized frameworks like McFly [[Paper]](https://doi.org/10.1016/j.softx.2020.100548) [[GitHub]](https://github.com/NLeSC/mcfly).
In the end, we obtained the best results using a simple [ResNet](https://arxiv.org/abs/1512.03385) in combination with the time-series framework tsai [[Doc]](https://timeseriesai.github.io/tsai/) [[GitHub]](https://github.com/timeseriesAI/tsai).

Here is a list of notebooks that deal with the topic of signal classification:

- `clustering-algos.ipynb` - testing a variety of traditional clustering algorithm on a reduced dataset size
- `Kmeans.ipynb` - [Time Series K-Means](https://tslearn.readthedocs.io/en/stable/auto_examples/clustering/plot_kmeans.html#k-means) algorithm of the [tslearn](https://tslearn.readthedocs.io/en/stable/index.html) library
- `KShape.ipynb` - [KShape](https://tslearn.readthedocs.io/en/stable/auto_examples/clustering/plot_kshape.html#kshape) algorithm of the [tslearn](https://tslearn.readthedocs.io/en/stable/index.html) library
- `SOM.ipynb` -  MiniSom, a minimalistic implementation of the [Self-Organizing Map](https://www.sciencedirect.com/science/article/pii/S0893608009800014) algorithm, of the [minisom](https://github.com/JustGlowing/minisom) library
- `mcfly-based-classification.ipynb` - McFly [[Paper]](https://doi.org/10.1016/j.softx.2020.100548) [[GitHub]](https://github.com/NLeSC/mcfly), a deep learning tool for time series classification and regression
- `time-series-ml-analyze.ipynb` - comparing many different machine learning and DNN algorithm using tsai [[Doc]](https://timeseriesai.github.io/tsai/) [[GitHub]](https://github.com/timeseriesAI/tsai) based on IBM Learning Path [Get started with the Time Series Classification API](https://developer.ibm.com/learningpaths/get-started-time-series-classification-api/).
- `time-series-dnn+uncertainty-analyze.ipynb` - further investigate the best trained ResNet of the `time-series-ml-analyze.ipynb` notebook w.r.t. basic model uncertainty
