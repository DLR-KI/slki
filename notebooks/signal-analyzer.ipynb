{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Analyzer\n",
    "\n",
    "This notebooks loads single signals and offers a simple GUI to plot them including some further analysis.\n",
    "\n",
    "The prerequisite is to have slki as well as its dependencies installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from _defaults import (\n",
    "    datasets_labels,\n",
    "    init_notebook,\n",
    "    load_datasets_chunk_lengths,\n",
    "    load_signal,\n",
    ")\n",
    "import numpy as np\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprecessed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do enforce resampling, there is an option for that inside the GUI later\n",
    "_defaults.resample_size = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse the data. To be presice: Analyse how many signals are avaliable without loading the signals to save memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[1;32mINFO\u001b[0m] \u001b[37m[slki.data.import][data_import.py:537]\u001b[0m  7 meta data files found.\n",
      "[\u001b[1;32mINFO\u001b[0m] \u001b[37m[slki.data.import][data_import.py:594]\u001b[0m  Loading meta data from '/home/lab/slki/Dataset/preprecessed/v4/fernverkehr-points-kionix-sh-z-dt_1-meta.pkl'...\n",
      "[\u001b[1;32mINFO\u001b[0m] \u001b[37m[slki.data.import][data_import.py:594]\u001b[0m  Loading meta data from '/home/lab/slki/Dataset/preprecessed/v4/fernverkehr-points-kionix-sh-z-dt_2-meta.pkl'...\n",
      "[\u001b[1;32mINFO\u001b[0m] \u001b[37m[slki.data.import][data_import.py:594]\u001b[0m  Loading meta data from '/home/lab/slki/Dataset/preprecessed/v4/fernverkehr-points-kionix-sh-z-dt_3-meta.pkl'...\n",
      "[\u001b[1;32mINFO\u001b[0m] \u001b[37m[slki.data.import][data_import.py:594]\u001b[0m  Loading meta data from '/home/lab/slki/Dataset/preprecessed/v4/fernverkehr-points-kionix-sh-z-dt_4-meta.pkl'...\n",
      "[\u001b[1;32mINFO\u001b[0m] \u001b[37m[slki.data.import][data_import.py:594]\u001b[0m  Loading meta data from '/home/lab/slki/Dataset/preprecessed/v4/fernverkehr-points-kionix-sh-z-dt_5-meta.pkl'...\n",
      "[\u001b[1;32mINFO\u001b[0m] \u001b[37m[slki.data.import][data_import.py:594]\u001b[0m  Loading meta data from '/home/lab/slki/Dataset/preprecessed/v4/fernverkehr-points-kionix-sh-z-dt_6-meta.pkl'...\n",
      "[\u001b[1;32mINFO\u001b[0m] \u001b[37m[slki.data.import][data_import.py:594]\u001b[0m  Loading meta data from '/home/lab/slki/Dataset/preprecessed/v4/fernverkehr-points-kionix-sh-z-dt_7-meta.pkl'...\n",
      "[\u001b[1;32mINFO\u001b[0m] \u001b[37m[slki.data.import][data_import.py:537]\u001b[0m  2 meta data files found.\n",
      "[\u001b[1;32mINFO\u001b[0m] \u001b[37m[slki.data.import][data_import.py:594]\u001b[0m  Loading meta data from '/home/lab/slki/Dataset/preprecessed/v4/gueterzuege-points-kionix-sh-z-dt_1-meta.pkl'...\n",
      "[\u001b[1;32mINFO\u001b[0m] \u001b[37m[slki.data.import][data_import.py:594]\u001b[0m  Loading meta data from '/home/lab/slki/Dataset/preprecessed/v4/gueterzuege-points-kionix-sh-z-dt_2-meta.pkl'...\n",
      "[\u001b[1;32mINFO\u001b[0m] \u001b[37m[slki.data.import][data_import.py:537]\u001b[0m  6 meta data files found.\n",
      "[\u001b[1;32mINFO\u001b[0m] \u001b[37m[slki.data.import][data_import.py:594]\u001b[0m  Loading meta data from '/home/lab/slki/Dataset/preprecessed/v4/regioverkehr-points-kionix-sh-z-dt_1-meta.pkl'...\n",
      "[\u001b[1;32mINFO\u001b[0m] \u001b[37m[slki.data.import][data_import.py:594]\u001b[0m  Loading meta data from '/home/lab/slki/Dataset/preprecessed/v4/regioverkehr-points-kionix-sh-z-dt_2-meta.pkl'...\n",
      "[\u001b[1;32mINFO\u001b[0m] \u001b[37m[slki.data.import][data_import.py:594]\u001b[0m  Loading meta data from '/home/lab/slki/Dataset/preprecessed/v4/regioverkehr-points-kionix-sh-z-dt_3-meta.pkl'...\n",
      "[\u001b[1;32mINFO\u001b[0m] \u001b[37m[slki.data.import][data_import.py:594]\u001b[0m  Loading meta data from '/home/lab/slki/Dataset/preprecessed/v4/regioverkehr-points-kionix-sh-z-dt_4-meta.pkl'...\n",
      "[\u001b[1;32mINFO\u001b[0m] \u001b[37m[slki.data.import][data_import.py:594]\u001b[0m  Loading meta data from '/home/lab/slki/Dataset/preprecessed/v4/regioverkehr-points-kionix-sh-z-dt_5-meta.pkl'...\n",
      "[\u001b[1;32mINFO\u001b[0m] \u001b[37m[slki.data.import][data_import.py:594]\u001b[0m  Loading meta data from '/home/lab/slki/Dataset/preprecessed/v4/regioverkehr-points-kionix-sh-z-dt_6-meta.pkl'...\n"
     ]
    }
   ],
   "source": [
    "dataset_lengths = load_datasets_chunk_lengths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset         Length\n",
      "------------  --------\n",
      "Fernverkehr       5572\n",
      "Güterzüge         1587\n",
      "Regioverkehr      4248\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    tabulate(\n",
    "        zip(datasets_labels, (sum(data_lengths) for data_lengths in dataset_lengths), strict=False),\n",
    "        headers=[\"Dataset\", \"Length\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from tslearn.preprocessing import TimeSeriesResampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[1;32mINFO\u001b[0m] \u001b[37m[slki.data.import][data_import.py:532]\u001b[0m  1 data files and 1 meta data files found.\n",
      "[\u001b[1;32mINFO\u001b[0m] \u001b[37m[slki.data.import][data_import.py:576]\u001b[0m  Loading data from '/home/lab/slki/Dataset/preprecessed/v4/fernverkehr-points-kionix-sh-z-dt_1.pkl'...\n",
      "[\u001b[1;32mINFO\u001b[0m] \u001b[37m[slki.data.import][data_import.py:594]\u001b[0m  Loading meta data from '/home/lab/slki/Dataset/preprecessed/v4/fernverkehr-points-kionix-sh-z-dt_1-meta.pkl'...\n",
      "[\u001b[1;32mINFO\u001b[0m] \u001b[37m[slki.data.import][data_import.py:334]\u001b[0m  Normalizing data with 'mone_one_zero_fix' normalization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f696e41e9af3432ca58c41f1d52fc62f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Normalizing:   0%|                                      | 0/843 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample, meta = load_signal(0, 0, dataset_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_widget = widgets.ToggleButtons(options=list(zip(datasets_labels, range(len(datasets_labels)), strict=False)))\n",
    "sample_idx_widget = widgets.BoundedIntText(value=0, min=0, max=sum(dataset_lengths[0]) - 1, step=1)\n",
    "sample_idx_max_widget = widgets.Label(value=f\"max: {sum(dataset_lengths[0]) - 1}\")\n",
    "resample_check_widget = widgets.Checkbox(value=False, indent=False)\n",
    "resample_widget = widgets.IntSlider(\n",
    "    value=len(sample), min=100, max=len(sample), step=100, readout=True, readout_format=\"d\", disabled=True\n",
    ")\n",
    "checkbox_kwargs = {\"value\": False, \"indent\": False, \"layout\": widgets.Layout(width=\"200px\")}\n",
    "outlier_reduction_widget = widgets.Checkbox(description=\"Outlier reduction\", **checkbox_kwargs)\n",
    "outlier_detection_widget = widgets.Checkbox(description=\"Outlier detection\", **checkbox_kwargs)\n",
    "peak_detection_widget = widgets.Checkbox(description=\"Peaks detection\", **checkbox_kwargs)\n",
    "eps_widget = widgets.IntSlider(value=50)\n",
    "grid_widget = widgets.GridBox(\n",
    "    [\n",
    "        widgets.Label(value=\"Dataset:\"),\n",
    "        dataset_widget,\n",
    "        widgets.Label(value=\"Sample:\"),\n",
    "        widgets.HBox([sample_idx_widget, sample_idx_max_widget]),\n",
    "        widgets.Label(value=\"Resample:\"),\n",
    "        widgets.HBox([resample_widget, resample_check_widget]),\n",
    "        widgets.Label(value=\"Flags:\"),\n",
    "        widgets.HBox(\n",
    "            [\n",
    "                widgets.VBox(\n",
    "                    [\n",
    "                        outlier_reduction_widget,\n",
    "                        outlier_detection_widget,\n",
    "                    ]\n",
    "                ),\n",
    "                peak_detection_widget,\n",
    "            ]\n",
    "        ),\n",
    "    ],\n",
    "    layout=widgets.Layout(grid_template_columns=\"100px auto\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(sample: np.ndarray):\n",
    "    fig, ax = plt.subplots(figsize=(20, 5))\n",
    "    ax.plot(sample)\n",
    "    plt.ylim(-1.1, 1.1)\n",
    "    fig.tight_layout()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dataset_idx = 0\n",
    "\n",
    "\n",
    "def update_sample_max_value(dataset_idx: int):\n",
    "    global current_dataset_idx\n",
    "    if current_dataset_idx == dataset_idx:\n",
    "        return None\n",
    "\n",
    "    current_dataset_idx = dataset_idx\n",
    "    max_idx = sum(dataset_lengths[dataset_idx]) - 1\n",
    "    sample_idx_max_widget.value = f\"max: {max_idx}\"\n",
    "    sample_idx_widget.max = max_idx\n",
    "    sample_idx_widget.value = min(sample_idx_widget.value, max_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_resample_widgets(sample_size: int, resample_size: int, resample: bool) -> int:\n",
    "    old_max = resample_widget.max\n",
    "    resample_widget.disabled = not resample\n",
    "\n",
    "    resample_widget.max = sample_size\n",
    "    if old_max == resample_size or resample_size >= sample_size:\n",
    "        resample_widget.value = sample_size\n",
    "    return resample_widget.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from slki.utils.peak import detect_upper_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outlier(sample: np.ndarray, ax: plt.Axes, ax2: plt.Axes, sample_length: int):\n",
    "    # detect and plot peaks\n",
    "    upper_peaks = detect_upper_peaks(sample, sample_length)\n",
    "    if upper_peaks.any():\n",
    "        ax.scatter(upper_peaks, sample[upper_peaks], marker=\"o\", color=\"tab:purple\", s=40, facecolors=\"none\")\n",
    "    lower_peaks = detect_upper_peaks(-sample, sample_length)\n",
    "    if lower_peaks.any():\n",
    "        ax.scatter(lower_peaks, sample[lower_peaks], marker=\"o\", color=\"tab:cyan\", s=40, facecolors=\"none\")\n",
    "    peaks = np.unique(np.sort(np.hstack((upper_peaks, lower_peaks))))\n",
    "    # box plot\n",
    "    sample_peaks = sample[peaks]\n",
    "    bxpstats = plt.cbook.boxplot_stats(sample_peaks)\n",
    "    ax2.bxp(\n",
    "        bxpstats,\n",
    "        widths=0.8,\n",
    "        vert=True,\n",
    "        flierprops={\"markeredgecolor\": \"tab:red\", \"linestyle\": \"none\", \"markerfacecolor\": \"tab:red\"},\n",
    "    )\n",
    "    ax2.set_xticklabels([\"peaks\"])\n",
    "    # draw boundary lines\n",
    "    lower_bound = bxpstats[0][\"whislo\"]\n",
    "    upper_bound = bxpstats[0][\"whishi\"]\n",
    "    ax.axhline(y=lower_bound, color=\"r\", linestyle=\"-\")\n",
    "    ax.axhline(y=upper_bound, color=\"r\", linestyle=\"-\")\n",
    "    # add colors to the different areas\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    patch_kwgars = {\"linewidth\": 1, \"edgecolor\": \"none\", \"facecolor\": \"r\", \"alpha\": 0.1}\n",
    "    ax.add_patch(Rectangle((xlim[0], ylim[0]), xlim[1], -ylim[0] + lower_bound, **patch_kwgars))\n",
    "    ax.add_patch(Rectangle((xlim[0], upper_bound), xlim[1], ylim[1] - upper_bound, **patch_kwgars))\n",
    "    # log details\n",
    "    fliers = bxpstats[0][\"fliers\"]\n",
    "    print(f\"Number of outliers: {len(fliers)}\")\n",
    "    print(f\"lower bound: {lower_bound},  upper bound: {upper_bound}\")\n",
    "    print(f\"Outlier values: {fliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from slki.utils.peak import PeaksClusteringResult, cluster_peaks, detect_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_peak_mean_distance(\n",
    "    signal: np.ndarray,\n",
    "    meta: dict[str, Any],\n",
    "    peaks: np.ndarray | None = None,\n",
    "    clustering_results: PeaksClusteringResult | None = None,\n",
    "):\n",
    "    sample_length: int = meta[\"sample_length\"]\n",
    "    peaks = peaks if peaks is not None else detect_peaks(signal, sample_length)\n",
    "    if clustering_results is None:\n",
    "        clustering_results = cluster_peaks(peaks, len(signal), sample_length)\n",
    "\n",
    "    unique_labels = set(clustering_results.labels)\n",
    "    cluster_centers = []\n",
    "    for label in unique_labels:\n",
    "        if label == -1:\n",
    "            continue  # skip noise points\n",
    "        label_mask = clustering_results.labels == label\n",
    "        x = peaks[label_mask]\n",
    "        pos = x[np.argmax(signal[x])]\n",
    "        cluster_centers.append(pos.tolist())\n",
    "    mean_dist = sum(b - a for a, b in zip(cluster_centers, cluster_centers[1:], strict=False)) / len(cluster_centers)\n",
    "    # print([b - a for a, b in zip(cluster_centers, cluster_centers[1:], strict=False)])\n",
    "\n",
    "    # mean_dist = sum(b - a for a, b in zip(peaks, peaks[1:])) / len(peaks)\n",
    "    print(\"Mean distance between peaks in sample rate:\", mean_dist)\n",
    "\n",
    "    # stage \"detect\" trims signal and sample_length but lets start and end time untouched\n",
    "    start_time: datetime = meta[\"start_time\"]\n",
    "    end_time: datetime = meta[\"end_time\"]\n",
    "    sample_rate_in_hz: float = meta[\"sample_rate_in_hz\"]  # sample rate correct?\n",
    "    resample_factor = sample_length / len(signal)\n",
    "\n",
    "    print(\"signal duration (based on sample rate):\", sample_length * resample_factor / sample_rate_in_hz, \"s\")\n",
    "    print(\"recorded signal duration (based on start end time)\", (end_time - start_time).total_seconds(), \"s\")\n",
    "\n",
    "    print(\"sample_rate_in_hz:\", sample_rate_in_hz)\n",
    "    print(\"sample_length:\", sample_length)\n",
    "\n",
    "    mean_dist_in_seconds = mean_dist * resample_factor / (sample_rate_in_hz)\n",
    "    print(\"Mean distance between peaks in seconds (based on sample rate):\", mean_dist_in_seconds)\n",
    "    print(f\"  =>  {15.0 / mean_dist_in_seconds} m/s  <=>  {15.0 * 3.6 / mean_dist_in_seconds} km/h\")\n",
    "\n",
    "    seconds = (end_time - start_time).total_seconds()\n",
    "    mean_dist_in_seconds = mean_dist * resample_factor * (seconds / sample_length)\n",
    "    print(\"Mean distance between peaks in seconds (based on start end time):\", mean_dist_in_seconds)\n",
    "    print(f\"  =>  {15.0 / mean_dist_in_seconds} m/s  <=>  {15.0 * 3.6 / mean_dist_in_seconds} km/h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slki.preprocessing.outlier import Outlier as OutlierReduction\n",
    "from slki.utils.peak import detect_and_cluster_and_plot_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_interaction(\n",
    "    dataset_idx: int,\n",
    "    sample_idx: int,\n",
    "    resample_size: int,\n",
    "    resample: bool,\n",
    "    peak_detection: bool,\n",
    "    outlier_detection: bool,\n",
    "    outlier_reduction: bool,\n",
    "):\n",
    "    # update widgets\n",
    "    update_sample_max_value(dataset_idx)\n",
    "    resample_size = update_resample_widgets(\n",
    "        len(load_signal(dataset_idx, sample_idx, dataset_lengths)[0]),\n",
    "        resample_size,\n",
    "        resample,\n",
    "    )\n",
    "    # get (resampled) signal\n",
    "    sample, meta = load_signal(dataset_idx, sample_idx, dataset_lengths)\n",
    "    sample = sample.copy()\n",
    "    if resample and len(sample) != resample_size:\n",
    "        sample = TimeSeriesResampler(resample_size).fit_transform(sample).flatten()\n",
    "        sample = sample / np.max(np.abs(sample))  # norm between [-1, 1]\n",
    "    if outlier_reduction:\n",
    "        OutlierReduction.from_data_and_meta(sample, meta).run_default()\n",
    "        sample = sample / np.max(np.abs(sample))  # norm between [-1, 1]\n",
    "\n",
    "    # plot sample\n",
    "    fig, ax = plot(sample)\n",
    "    # detect peaks + plotting\n",
    "    if peak_detection:\n",
    "        clustering_results, *_, peaks = detect_and_cluster_and_plot_peaks(\n",
    "            sample, meta[\"sample_length\"], ax, print_console=True\n",
    "        )\n",
    "        calc_peak_mean_distance(sample, meta, peaks, clustering_results)\n",
    "    # detect outlier\n",
    "    if outlier_detection:\n",
    "        ax2 = fig.add_axes([1.025, 0.08, 0.05, 0.89])\n",
    "        plt.ylim(-1.1, 1.1)\n",
    "        detect_outlier(sample, ax, ax2, meta[\"sample_length\"])\n",
    "    plt.show()\n",
    "    # outlier_str = \"on\" if outlier_reduction else \"off\"\n",
    "    # fig.savefig(f\"../results/plots/signal-{sample_idx:0>2}-outlier-{outlier_str}.png\")\n",
    "    # print(meta[\"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_widget = widgets.interactive_output(\n",
    "    handle_interaction,\n",
    "    dict(\n",
    "        dataset_idx=dataset_widget,\n",
    "        sample_idx=sample_idx_widget,\n",
    "        resample_size=resample_widget,\n",
    "        resample=resample_check_widget,\n",
    "        peak_detection=peak_detection_widget,\n",
    "        outlier_detection=outlier_detection_widget,\n",
    "        outlier_reduction=outlier_reduction_widget,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4b3238af464268834b5207c4dc95ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(Label(value='Dataset:'), ToggleButtons(options=(('Fernverkehr', 0), ('Güterzüge', 1), ('Regi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5107698c33634ababdaf82c0b7e64ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(grid_widget, plot_widget)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
